from scraper import scrape_and_chunk
from faiss_manager import save_faiss_index, save_chunks, load_faiss_index, load_chunks
from gemini_rag import rag_pipeline
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

dimension = 384
model = SentenceTransformer("all-MiniLM-L6-v2")

# Load existing FAISS index and chunks
chunks = load_chunks()
index = load_faiss_index(dimension)

if not chunks or index.ntotal == 0:
    print("‚ö° Creating new FAISS index...")
    urls = [
    "https://en.wikipedia.org/wiki/Generative_artificial_intelligence",
    "https://arxiv.org/list/cs.AI/recent",
    "https://openai.com/research/",
    "https://ai.googleblog.com/",
    "https://www.technologyreview.com/topic/artificial-intelligence/",
    "https://venturebeat.com/category/ai/",
     "https://huggingface.co/blog",
    "https://www.ibm.com/topics/artificial-intelligence",  # ‚úÖ IBM AI Learning
    "https://aws.amazon.com/machine-learning/",  # ‚úÖ AWS AI Guides
    "https://developers.google.com/machine-learning/",  # ‚úÖ Google AI Developer Tutorials
    "https://www.coursera.org/browse/data-science/ai",  # ‚úÖ AI Courses & Learning
]

    chunks = scrape_and_chunk(urls)

    # ‚úÖ Ensure scraped content has multiple chunks before continuing
    if len(chunks) < 2:
        print("‚ùå Error: Scraped content is too small! Try a different source.")
        exit()

    # ‚úÖ Generate embeddings and normalize them
    embeddings = model.encode(chunks)
    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)  # ‚úÖ Normalize embeddings

    # ‚úÖ Load or create FAISS index with cosine similarity
    index = faiss.IndexFlatIP(dimension)

    # ‚úÖ Ensure FAISS index receives multiple vectors
    if embeddings.shape[0] > 1:
        index.add(np.array(embeddings))  # ‚úÖ Add normalized embeddings
        save_faiss_index(index)
        save_chunks(chunks)
        print(f"‚úÖ FAISS index updated with {index.ntotal} vectors.")
    else:
        print("‚ùå Error: FAISS did not receive enough embeddings! Check chunking.")
        exit()
else:
    print(f"‚úÖ FAISS index already exists with {index.ntotal} vectors.")

# Example query
user_query = "What is generative artificial intelligence?"
answer = rag_pipeline(user_query)
print("\nüîπ AI-Powered Response:\n", answer)
